{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import mat73\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os.path\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# self-made functions\n",
    "from preprocessing_utils import *\n",
    "from centers_utils import *\n",
    "# from classification_utils import *\n",
    "\n",
    "# use to reload external python file\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = [-200, 0] # in ms\n",
    "frame = [0, 600] # in ms\n",
    "elec_to_keep = ['FP1', 'FP2', 'F3', 'FZ', 'F4', 'T7', 'Cz', 'T8', 'P7', 'P8', 'O1', 'Oz', 'O2']\n",
    "sub_num = '01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg = mat73.loadmat(\"data/s\" + sub_num + \".mat\")\n",
    "train_target, train_nontarget, test_target, test_nontarget = processSessionsIndiv(eeg, baseline, frame, elec_to_keep, opt_keep_baseline=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Center Functions with Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches what we expect: https://ieeexplore.ieee.org/document/8013808\n",
    "def euclidean_mean_timing(P_set):\n",
    "    start = time.time()\n",
    "    mean = np.mean(P_set, axis=0)\n",
    "    end = time.time()\n",
    "    return mean, (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from: https://github.com/pyRiemann/pyRiemann/blob/master/pyriemann/utils/mean.py#L22 \n",
    "# derived from: https://link.springer.com/chapter/10.1007/978-3-642-00826-9_6 \n",
    "# find riemannian mean using gradient descent \n",
    "def riemannian_mean_timing(P_set, max_iter=50, nu=1.0, tol=10e-9, weights=None):\n",
    "    tau = np.finfo(np.float64).max\n",
    "    crit = np.finfo(np.float64).max\n",
    "    timing = []\n",
    "\n",
    "    mean_curr = euclidean_mean(P_set)\n",
    "    n_trials, n_cov, _ = P_set.shape\n",
    "\n",
    "    if weights == None:\n",
    "        weights = np.ones(n_trials) / n_trials # evenly weigh all trials\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        start = time.time()\n",
    "        mean_sqrt = sqrtm(mean_curr)\n",
    "        grad = grad_riemann_mean(P_set, mean_curr, weights)\n",
    "        mean_curr = mean_sqrt @ expm(nu * grad) @ mean_sqrt\n",
    "\n",
    "        # this is taken directly from the first link\n",
    "        crit = np.linalg.norm(grad, ord='fro')\n",
    "        h = nu * crit\n",
    "        if h < tau:\n",
    "            nu = 0.95 * nu\n",
    "            tau = h\n",
    "        else:\n",
    "            nu = 0.5 * nu\n",
    "        end = time.time()\n",
    "        timing.append(end - start)\n",
    "\n",
    "        if crit <= tol or nu <= tol:\n",
    "            break\n",
    "\n",
    "    return mean_curr, timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.sciencedirect.com/science/article/pii/S0377042711005218\n",
    "# uses ADMM + proximal update to do the update\n",
    "def matrix_median_timing(P_set, lam=0, gamma=1, max_iter=200, tol=10e-9):\n",
    "    n_trials, n_cov, _ = P_set.shape\n",
    "\n",
    "    mat_rn = np.zeros((n_cov, n_cov))\n",
    "    mat_rn = mat_rn.T @ mat_rn\n",
    "\n",
    "    V_curr = np.tile(mat_rn, (n_trials,1,1)) \n",
    "\n",
    "    mat_rn = np.zeros((n_cov, n_cov)) \n",
    "    mat_rn = mat_rn.T @ mat_rn\n",
    "    B_curr = np.tile(mat_rn, (n_trials,1,1))\n",
    "    \n",
    "    mat_rn = np.zeros((n_cov, n_cov)) \n",
    "    mat_rn = mat_rn.T @ mat_rn\n",
    "    S_curr = np.tile(mat_rn, (n_trials,1,1))\n",
    "\n",
    "    X_curr = euclidean_mean(P_set) # informed start\n",
    "    X_prev = X_curr\n",
    "\n",
    "    timing = []\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        start = time.time()\n",
    "        # X update\n",
    "        X_prev = X_curr\n",
    "        X_curr = np.linalg.inv((lam*gamma + n_trials)*np.identity(n_cov)) @ (np.sum(V_curr - B_curr, axis=0))\n",
    "\n",
    "        # termination condition\n",
    "        if np.linalg.norm(np.abs(X_curr - X_prev), ord='fro') < tol:\n",
    "            end = time.time()\n",
    "            timing.append(end-start)\n",
    "            break\n",
    "\n",
    "        # V update through proximal update on Y\n",
    "        Y_curr = V_curr - P_set\n",
    "        S_curr = B_curr + np.tile(X_curr, (n_trials,1,1)) - P_set\n",
    "        S_norm = np.linalg.norm(S_curr, axis=(1,2), ord='fro')\n",
    "        Y_new = np.zeros(Y_curr.shape)\n",
    "        prox_mult = np.tile((1 - (gamma/S_norm)), (n_cov, n_cov, 1))\n",
    "        prox_mult = np.moveaxis(prox_mult,-1,0)\n",
    "        greater_idx = S_norm >= gamma\n",
    "        Y_new[greater_idx] = prox_mult[greater_idx] * S_curr[greater_idx]\n",
    "        Y_curr = Y_new  \n",
    "        V_curr = Y_curr + P_set # update V_curr\n",
    "\n",
    "        # B update - dual update\n",
    "        B_curr = B_curr + np.tile(X_curr, (n_trials,1,1)) - V_curr\n",
    "\n",
    "        end = time.time()\n",
    "        timing.append(end-start)\n",
    "\n",
    "    return X_curr, timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://www.sciencedirect.com/science/article/pii/S1053811908012019?via%3Dihub \n",
    "# uses steepest descent\n",
    "# directly from: https://github.com/pyRiemann/pyRiemann/blob/master/pyriemann/utils/median.py\n",
    "def riemannian_median_timing(P_set, nu=1, max_iter=50, tol=10e-9, weights=None):\n",
    "    n_trials, n_cov, _ = P_set.shape\n",
    "\n",
    "    curr_med = euclidean_mean(P_set)\n",
    "\n",
    "    timing = []\n",
    "\n",
    "    if weights == None:\n",
    "        weights = np.ones(n_trials) / n_trials # evenly weigh all trials\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        start = time.time()\n",
    "        distances = np.array([riemannian_distance(P_indiv, curr_med) for P_indiv in P_set])\n",
    "        is_nonzero = (~(distances == 0))\n",
    "        nonzero_weights = weights[is_nonzero] / distances[is_nonzero]\n",
    "\n",
    "        med_sqrt = sqrtm(curr_med)\n",
    "        med_invsqrt = invsqrtm(curr_med)\n",
    "        tangent_vecs = logm(med_invsqrt @ P_set[is_nonzero] @ med_invsqrt)\n",
    "        grad = np.einsum('a,abc->bc', nonzero_weights / np.sum(nonzero_weights), tangent_vecs)\n",
    "        curr_med = med_sqrt @ expm(nu * grad) @ med_sqrt\n",
    "\n",
    "        crit = np.linalg.norm(grad, ord='fro')\n",
    "        end = time.time()\n",
    "        timing.append(end-start)\n",
    "        if crit <= tol:\n",
    "            break\n",
    "\n",
    "    return curr_med, timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://ieeexplore.ieee.org/abstract/document/7523317\n",
    "def huber_centroid_timing(P_set, alpha=0.25, mu=0.5, nu_init=0.5, max_iter=50, tol=10e-9): \n",
    "    n_trials, n_cov, _ = P_set.shape\n",
    "    curr = euclidean_mean(P_set)\n",
    "    nu = nu_init\n",
    "\n",
    "    timing = []\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        start = time.time()\n",
    "        grad = huber_grad(P_set, curr)\n",
    "\n",
    "        # attempt at Armijo backsearching - need to check update\n",
    "        # while huber_obj(P_set, exp_map(curr, -nu*grad)) > (huber_obj(P_set, curr) + nu*np.sum(huber_grad(P_set,curr)*exp_map(curr, -grad))):\n",
    "        #     nu = mu * nu\n",
    "\n",
    "        curr = exp_map(curr, -nu*grad)\n",
    "        crit = np.linalg.norm(grad, ord='fro')\n",
    "        end = time.time()\n",
    "        timing.append(end-start)\n",
    "        if crit <= tol:\n",
    "            break\n",
    "\n",
    "    return curr, timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Timing of One Iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 26, 26)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_test = train_nontarget[0]\n",
    "P_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of one iteration (s): 0.000997781753540039\n",
      "Number of iterations: 1\n"
     ]
    }
   ],
   "source": [
    "_, euclid_mean_time = euclidean_mean_timing(P_test)\n",
    "print(\"Time of one iteration (s):\", np.mean(euclid_mean_time))\n",
    "print(\"Number of iterations:\", 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of one iteration (s): 0.04880280494689941\n",
      "Number of iterations: 15\n"
     ]
    }
   ],
   "source": [
    "_, riemann_mean_time = riemannian_mean_timing(P_test)\n",
    "print(\"Time of one iteration (s):\", np.mean(riemann_mean_time))\n",
    "print(\"Number of iterations:\", len(riemann_mean_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of one iteration (s): 0.02243238442564664\n",
      "Number of iterations: 146\n"
     ]
    }
   ],
   "source": [
    "_, mat_med_time = matrix_median_timing(P_test)\n",
    "print(\"Time of one iteration (s):\", np.mean(mat_med_time))\n",
    "print(\"Number of iterations:\", len(mat_med_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of one iteration (s): 0.1380513572692871\n",
      "Number of iterations: 50\n"
     ]
    }
   ],
   "source": [
    "_, riemann_med_time = riemannian_median_timing(P_test)\n",
    "print(\"Time of one iteration (s):\", np.mean(riemann_med_time))\n",
    "print(\"Number of iterations:\", len(riemann_med_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of one iteration (s): 0.17463696479797364\n",
      "Number of iterations: 50\n"
     ]
    }
   ],
   "source": [
    "_, huber_time = huber_centroid_timing(P_test)\n",
    "print(\"Time of one iteration (s):\", np.mean(huber_time))\n",
    "print(\"Number of iterations:\", len(huber_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
