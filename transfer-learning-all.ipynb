{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import mat73\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os.path\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# self-made functions\n",
    "from preprocessing_utils import *\n",
    "from centers_utils import *\n",
    "from classification_utils import *\n",
    "\n",
    "# use to reload external python file\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n = 5 subjects\n",
    "\n",
    "session: 5 subjects x 2 train x 4 test = 40 \n",
    "\n",
    "subject: (5_C_2) x 2 x 2 train x 4 test = 160\n",
    "\n",
    "task: 5 subjects x 1 rsvp x 4 test = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to do Transfer Learning on all Types and Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_tl(sub_num, baseline, frame, elec_to_keep):\n",
    "    cent_opts = ['euclid_mean', 'riemann_mean', 'mat_med', 'riemann_med', 'huber']\n",
    "    eeg = mat73.loadmat(\"data/s\" + sub_num + \".mat\")\n",
    "    train_target, train_nontarget, test_target, test_nontarget = processSessionsIndiv(eeg, baseline, frame, elec_to_keep, opt_keep_baseline=False)\n",
    "    \n",
    "    train_sess_num = train_target.shape[0]\n",
    "    test_sess_num = test_target.shape[0]\n",
    "    for train_idx in range(train_sess_num):\n",
    "        for test_idx in range(test_sess_num):\n",
    "            for cent in cent_opts:\n",
    "                # pre TL\n",
    "                pre_res = get_class_results(train_nontarget[train_idx,:], train_target[train_idx,:], test_nontarget[test_idx,:], test_target[test_idx,:], tl_bool=False, cent_type=cent)\n",
    "                if os.path.exists('results/pre_session_' + cent + '.csv'):\n",
    "                    action = 'a'\n",
    "                else:\n",
    "                    action = 'w'\n",
    "                with open('results/pre_session_' + cent + '.csv', action, newline='') as csvfile:\n",
    "                    csv_writer = csv.writer(csvfile, delimiter=',',\n",
    "                                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(pre_res)\n",
    "                \n",
    "                # post TL\n",
    "                post_res = get_class_results(train_nontarget[train_idx,:], train_target[train_idx,:], test_nontarget[test_idx,:], test_target[test_idx,:], tl_bool=True, cent_type=cent)\n",
    "                if os.path.exists('results/post_session_' + cent + '.csv'):\n",
    "                    action = 'a'\n",
    "                else:\n",
    "                    action = 'w'\n",
    "                with open('results/post_session_' + cent + '.csv', action, newline='') as csvfile:\n",
    "                    csv_writer = csv.writer(csvfile, delimiter=',',\n",
    "                                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(post_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_tl(sub1_num, sub2_num, baseline, frame, elec_to_keep):\n",
    "    cent_opts = ['euclid_mean', 'riemann_mean', 'mat_med', 'riemann_med', 'huber']\n",
    "    eeg1 = mat73.loadmat(\"data/s\" + sub1_num + \".mat\")\n",
    "    train_target1, train_nontarget1, test_target1, test_nontarget1 = processSessionsIndiv(eeg1, baseline, frame, elec_to_keep, opt_keep_baseline=False)\n",
    "    eeg2 = mat73.loadmat(\"data/s\" + sub2_num + \".mat\")\n",
    "    train_target2, train_nontarget2, test_target2, test_nontarget2 = processSessionsIndiv(eeg2, baseline, frame, elec_to_keep, opt_keep_baseline=False)\n",
    "\n",
    "    # train using 1, test using 2\n",
    "    train_sess_num = train_target1.shape[0]\n",
    "    test_sess_num = test_target2.shape[0]\n",
    "    for train_idx in range(train_sess_num):\n",
    "        for test_idx in range(test_sess_num):\n",
    "            for cent in cent_opts:\n",
    "                # pre TL\n",
    "                pre_res = get_class_results(train_nontarget1[train_idx,:], train_target1[train_idx,:], test_nontarget2[test_idx,:], test_target2[test_idx,:], tl_bool=False, cent_type=cent)\n",
    "                if os.path.exists('results/pre_subject_' + cent + '.csv'):\n",
    "                    action = 'a'\n",
    "                else:\n",
    "                    action = 'w'\n",
    "                with open('results/pre_subject_' + cent + '.csv', action, newline='') as csvfile:\n",
    "                    csv_writer = csv.writer(csvfile, delimiter=',',\n",
    "                                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(pre_res)\n",
    "                \n",
    "                # post TL\n",
    "                post_res = get_class_results(train_nontarget1[train_idx,:], train_target1[train_idx,:], test_nontarget2[test_idx,:], test_target2[test_idx,:], tl_bool=True, cent_type=cent)\n",
    "                if os.path.exists('results/post_subject_' + cent + '.csv'):\n",
    "                    action = 'a'\n",
    "                else:\n",
    "                    action = 'w'\n",
    "                with open('results/post_subject_' + cent + '.csv', action, newline='') as csvfile:\n",
    "                    csv_writer = csv.writer(csvfile, delimiter=',',\n",
    "                                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(post_res)\n",
    "\n",
    "    # train using 2, test using 1\n",
    "    train_sess_num = train_target2.shape[0]\n",
    "    test_sess_num = test_target1.shape[0]\n",
    "    for train_idx in range(train_sess_num):\n",
    "        for test_idx in range(test_sess_num):\n",
    "            for cent in cent_opts:\n",
    "                # pre TL\n",
    "                pre_res = get_class_results(train_nontarget2[train_idx,:], train_target2[train_idx,:], test_nontarget1[test_idx,:], test_target1[test_idx,:], tl_bool=False, cent_type=cent)\n",
    "                if os.path.exists('results/pre_subject_' + cent + '.csv'):\n",
    "                    action = 'a'\n",
    "                else:\n",
    "                    action = 'w'\n",
    "                with open('results/pre_subject_' + cent + '.csv', action, newline='') as csvfile:\n",
    "                    csv_writer = csv.writer(csvfile, delimiter=',',\n",
    "                                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(pre_res)\n",
    "                \n",
    "                # post TL\n",
    "                post_res = get_class_results(train_nontarget2[train_idx,:], train_target2[train_idx,:], test_nontarget1[test_idx,:], test_target1[test_idx,:], tl_bool=True, cent_type=cent)\n",
    "                if os.path.exists('results/post_subject_' + cent + '.csv'):\n",
    "                    action = 'a'\n",
    "                else:\n",
    "                    action = 'w'\n",
    "                with open('results/post_subject_' + cent + '.csv', action, newline='') as csvfile:\n",
    "                    csv_writer = csv.writer(csvfile, delimiter=',',\n",
    "                                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(post_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_tl(sub_num, baseline, frame, elec_to_keep):\n",
    "    cent_opts = ['euclid_mean', 'riemann_mean', 'mat_med', 'riemann_med', 'huber']\n",
    "    eeg = mat73.loadmat(\"data/s\" + sub_num + \".mat\")\n",
    "    _, _, test_target, test_nontarget = processSessionsIndiv(eeg, baseline, frame, elec_to_keep, opt_keep_baseline=False)\n",
    "    train_target, train_nontarget = processRSVP(eeg, baseline, frame, elec_to_keep, opt_keep_baseline=False)\n",
    "    \n",
    "    test_sess_num = test_target.shape[0]\n",
    "    for test_idx in range(test_sess_num):\n",
    "        for cent in cent_opts:\n",
    "            # pre TL\n",
    "            pre_res = get_class_results(train_nontarget, train_target, test_nontarget[test_idx,:], test_target[test_idx,:], tl_bool=False, cent_type=cent)\n",
    "            if os.path.exists('results/pre_task_' + cent + '.csv'):\n",
    "                action = 'a'\n",
    "            else:\n",
    "                action = 'w'\n",
    "            with open('results/pre_task_' + cent + '.csv', action, newline='') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile, delimiter=',',\n",
    "                                        quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(pre_res)\n",
    "            \n",
    "            # post TL\n",
    "            post_res = get_class_results(train_nontarget, train_target, test_nontarget[test_idx,:], test_target[test_idx,:], tl_bool=True, cent_type=cent)\n",
    "            if os.path.exists('results/post_task_' + cent + '.csv'):\n",
    "                action = 'a'\n",
    "            else:\n",
    "                action = 'w'\n",
    "            with open('results/post_task_' + cent + '.csv', action, newline='') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile, delimiter=',',\n",
    "                                        quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(post_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = [-200, 0] # in ms\n",
    "frame = [0, 600] # in ms\n",
    "# elec_to_keep = ['FP1', 'FP2', 'F3', 'FZ', 'F4', 'T7', 'Cz', 'T8', 'P7', 'P3', 'Pz', 'P4', 'P8', 'O1', 'Oz', 'O2']\n",
    "elec_to_keep = ['FP1', 'FP2', 'F3', 'FZ', 'F4', 'T7', 'Cz', 'T8', 'P7', 'P8', 'O1', 'Oz', 'O2']\n",
    "subjects = ['01', '25', '38', '52', '54']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~70 min\n",
    "for sub in subjects:\n",
    "    session_tl(sub, baseline, frame, elec_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~280 min\n",
    "for idx_1 in range(len(subjects)):\n",
    "    for idx_2 in range(len(subjects)):\n",
    "        if idx_2 > idx_1:\n",
    "            subject_tl(subjects[idx_1], subjects[idx_2], baseline, frame, elec_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~30 min\n",
    "for sub in subjects:\n",
    "    task_tl(sub, baseline, frame, elec_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chance\n",
    "def get_chance_perf(iters):\n",
    "    chance_perf_stats = np.asarray([0,0,0])\n",
    "\n",
    "    for i in range(iters):\n",
    "        n_nontarget = 1050\n",
    "        n_target = 210\n",
    "        y_test = np.hstack([np.zeros(n_nontarget), np.ones(n_target)])\n",
    "\n",
    "        test_chance = chance_perf(n_nontarget, n_target)\n",
    "        confus = get_confusion_mat(test_chance, y_test, n_nontarget, n_target, if_plot=False)\n",
    "        chance_perf_stats = chance_perf_stats + np.asarray(get_stats(confus))\n",
    "    \n",
    "    return chance_perf_stats / iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_chance_perf = get_chance_perf(40)\n",
    "subject_chance_perf = get_chance_perf(160)\n",
    "task_chance_perf = get_chance_perf(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_name):\n",
    "    acc = []\n",
    "    sens = [] \n",
    "    spec = []\n",
    "    with open(file_name, mode ='r')as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        for lines in csvFile:\n",
    "                acc.append(float(lines[0]))\n",
    "                sens.append(float(lines[1]))\n",
    "                spec.append(float(lines[2]))\n",
    "\n",
    "    return acc, sens, spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_res(file_type, chance_perf_data):\n",
    "\n",
    "    cent_opts = ['euclid_mean', 'riemann_mean', 'mat_med', 'riemann_med', 'huber']\n",
    "    cent_names = [\"Euclidean\\nMean\", \"Riemannian\\nMean\", \"Matrix\\nMedian\", \"Riemannian\\nMedian\", \"Huber\\nCentroid\"]\n",
    "\n",
    "    pre_acc_list = []\n",
    "    pre_sens_list = []\n",
    "    pre_spec_list = []\n",
    "    for cent in cent_opts: \n",
    "        acc, sens, spec = get_data(\"results/pre_\" + file_type + \"_\" + cent + \".csv\")\n",
    "        pre_acc_list.append(acc)\n",
    "        pre_sens_list.append(sens)\n",
    "        pre_spec_list.append(spec)\n",
    "\n",
    "    post_acc_list = []\n",
    "    post_sens_list = []\n",
    "    post_spec_list = []\n",
    "    for cent in cent_opts: \n",
    "        acc, sens, spec = get_data(\"results/post_\" + file_type + \"_\" + cent + \".csv\")\n",
    "        post_acc_list.append(acc)\n",
    "        post_sens_list.append(sens)\n",
    "        post_spec_list.append(spec)\n",
    "\n",
    "    pre_acc_df = pd.DataFrame(np.asarray(pre_acc_list).T, columns=cent_names)\n",
    "    pre_acc_df = pre_acc_df.assign(TL=['Pre']*len(pre_acc_df))\n",
    "    pre_sens_df = pd.DataFrame(np.asarray(pre_sens_list).T, columns=cent_names)\n",
    "    pre_sens_df = pre_sens_df.assign(TL=['Pre']*len(pre_sens_df))\n",
    "    pre_spec_df = pd.DataFrame(np.asarray(pre_spec_list).T, columns=cent_names)\n",
    "    pre_spec_df = pre_spec_df.assign(TL=['Pre']*len(pre_spec_df))\n",
    "\n",
    "    post_acc_df = pd.DataFrame(np.asarray(post_acc_list).T, columns=cent_names)\n",
    "    post_acc_df = post_acc_df.assign(TL=['Post']*len(post_acc_df))\n",
    "    post_sens_df = pd.DataFrame(np.asarray(post_sens_list).T, columns=cent_names)\n",
    "    post_sens_df = post_sens_df.assign(TL=['Post']*len(post_sens_df))\n",
    "    post_spec_df = pd.DataFrame(np.asarray(post_spec_list).T, columns=cent_names)\n",
    "    post_spec_df = post_spec_df.assign(TL=['Post']*len(post_spec_df))\n",
    "\n",
    "    acc_df = pd.concat([pre_acc_df, post_acc_df])\n",
    "    sens_df = pd.concat([pre_sens_df, post_sens_df])\n",
    "    spec_df = pd.concat([pre_spec_df, post_spec_df])\n",
    "\n",
    "    acc_df = acc_df.rename(columns={\"TL\": \"Transfer\\nLearning\"})\n",
    "    sens_df = sens_df.rename(columns={\"TL\": \"Transfer\\nLearning\"})\n",
    "    spec_df = spec_df.rename(columns={\"TL\": \"Transfer\\nLearning\"})\n",
    "\n",
    "    ax = sns.boxplot(data=pd.melt(acc_df, id_vars=\"Transfer\\nLearning\", value_vars=cent_names, var_name=\"Centers\", value_name=\"Accuracy\"), \n",
    "                x=\"Centers\",\n",
    "                y=\"Accuracy\", \n",
    "                hue=\"Transfer\\nLearning\", \n",
    "                palette=sns.color_palette(\"hls\", 2))\n",
    "    ax.axhline(chance_perf_data[0], color=\".3\", dashes=(2,2))\n",
    "    ax.set_title(\"Accuracy\")\n",
    "    sns.move_legend(ax, \"center right\", bbox_to_anchor=(1.2, 0.5))\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig(file_type + \"_acc.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    ax = sns.boxplot(data=pd.melt(sens_df, id_vars=\"Transfer\\nLearning\", value_vars=cent_names, var_name=\"Centers\", value_name=\"Sensitivity\"), \n",
    "                x=\"Centers\",\n",
    "                y=\"Sensitivity\", \n",
    "                hue=\"Transfer\\nLearning\", \n",
    "                palette=sns.color_palette(\"hls\", 2))\n",
    "    ax.axhline(chance_perf_data[1], color=\".3\", dashes=(2,2))\n",
    "    ax.set_title(\"Sensitivity\")\n",
    "    sns.move_legend(ax, \"center right\", bbox_to_anchor=(1.2, 0.5))\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig(file_type + \"_sens.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    ax = sns.boxplot(data=pd.melt(spec_df, id_vars=\"Transfer\\nLearning\", value_vars=cent_names, var_name=\"Centers\", value_name=\"Specificity\"), \n",
    "                x=\"Centers\",\n",
    "                y=\"Specificity\", \n",
    "                hue=\"Transfer\\nLearning\", \n",
    "                palette=sns.color_palette(\"hls\", 2))\n",
    "    ax.axhline(chance_perf_data[2], color=\".3\", dashes=(2,2))\n",
    "    ax.set_title(\"Specificity\")\n",
    "    sns.move_legend(ax, \"center right\", bbox_to_anchor=(1.2, 0.5))\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig(file_type + \"_spec.png\", bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res('session', session_chance_perf)\n",
    "plot_res('subject', subject_chance_perf)\n",
    "plot_res('task', task_chance_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: omit outliers since outliers are quite extreme\n",
    "def plot_change_res(file_type):\n",
    "\n",
    "    cent_opts = ['euclid_mean', 'riemann_mean', 'mat_med', 'riemann_med', 'huber']\n",
    "    cent_names = [\"Euclidean\\nMean\", \"Riemannian\\nMean\", \"Matrix\\nMedian\", \"Riemannian\\nMedian\", \"Huber\\nCentroid\"]\n",
    "\n",
    "    pre_acc_list = []\n",
    "    pre_sens_list = []\n",
    "    pre_spec_list = []\n",
    "    for cent in cent_opts: \n",
    "        acc, sens, spec = get_data(\"results/pre_\" + file_type + \"_\" + cent + \".csv\")\n",
    "        pre_acc_list.append(acc)\n",
    "        pre_sens_list.append(sens)\n",
    "        pre_spec_list.append(spec)\n",
    "\n",
    "    post_acc_list = []\n",
    "    post_sens_list = []\n",
    "    post_spec_list = []\n",
    "    for cent in cent_opts: \n",
    "        acc, sens, spec = get_data(\"results/post_\" + file_type + \"_\" + cent + \".csv\")\n",
    "        post_acc_list.append(acc)\n",
    "        post_sens_list.append(sens)\n",
    "        post_spec_list.append(spec)\n",
    "\n",
    "    change_acc_df = pd.DataFrame((np.asarray(post_acc_list).T - np.asarray(pre_acc_list).T)/np.asarray(pre_acc_list).T, columns=cent_names)\n",
    "    change_acc_df = change_acc_df.assign(Metric=['Accuracy']*len(change_acc_df))\n",
    "    change_sens_df = pd.DataFrame((np.asarray(post_sens_list).T - np.asarray(pre_sens_list).T)/np.asarray(pre_sens_list).T, columns=cent_names)\n",
    "    change_sens_df = change_sens_df.assign(Metric=['Sensitivity']*len(change_sens_df))\n",
    "    change_spec_df = pd.DataFrame((np.asarray(post_spec_list).T - np.asarray(pre_spec_list).T)/np.asarray(pre_spec_list).T, columns=cent_names)\n",
    "    change_spec_df = change_spec_df.assign(Metric=['Specificity']*len(change_spec_df))\n",
    "\n",
    "    metric_df = pd.concat([change_acc_df, change_sens_df, change_spec_df])\n",
    "   \n",
    "    ax = sns.boxplot(data=pd.melt(metric_df, id_vars=\"Metric\", value_vars=cent_names, var_name=\"Centers\", value_name=\"Change in Performance After Transfer Learning\"), \n",
    "                x=\"Centers\",\n",
    "                y=\"Change in Performance After Transfer Learning\", \n",
    "                hue=\"Metric\", \n",
    "                palette=sns.color_palette(\"hls\", 3),\n",
    "                showfliers = False)\n",
    "    # ax.set_title(\"Change in Performance\")\n",
    "    sns.move_legend(ax, \"center right\", bbox_to_anchor=(1.3, 0.5))\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig(file_type + \"_change.png\", bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanna\\AppData\\Local\\Temp\\ipykernel_36980\\3199667699.py:26: RuntimeWarning: divide by zero encountered in divide\n",
      "  change_sens_df = pd.DataFrame((np.asarray(post_sens_list).T - np.asarray(pre_sens_list).T)/np.asarray(pre_sens_list).T, columns=cent_names)\n",
      "C:\\Users\\hanna\\AppData\\Local\\Temp\\ipykernel_36980\\3199667699.py:26: RuntimeWarning: invalid value encountered in divide\n",
      "  change_sens_df = pd.DataFrame((np.asarray(post_sens_list).T - np.asarray(pre_sens_list).T)/np.asarray(pre_sens_list).T, columns=cent_names)\n"
     ]
    }
   ],
   "source": [
    "plot_change_res('session')\n",
    "plot_change_res('subject')\n",
    "plot_change_res('task')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res_stats(file_type, chance_perf_data):\n",
    "\n",
    "    cent_opts = ['euclid_mean', 'riemann_mean', 'mat_med', 'riemann_med', 'huber']\n",
    "    cent_names = [\"Euclidean\\nMean\", \"Riemannian\\nMean\", \"Matrix\\nMedian\", \"Riemannian\\nMedian\", \"Huber\\nCentroid\"]\n",
    "\n",
    "    pre_acc_list = []\n",
    "    pre_sens_list = []\n",
    "    pre_spec_list = []\n",
    "    for cent in cent_opts: \n",
    "        acc, sens, spec = get_data(\"results/pre_\" + file_type + \"_\" + cent + \".csv\")\n",
    "        pre_acc_list.append(acc)\n",
    "        pre_sens_list.append(sens)\n",
    "        pre_spec_list.append(spec)\n",
    "\n",
    "    post_acc_list = []\n",
    "    post_sens_list = []\n",
    "    post_spec_list = []\n",
    "    for cent in cent_opts: \n",
    "        acc, sens, spec = get_data(\"results/post_\" + file_type + \"_\" + cent + \".csv\")\n",
    "        post_acc_list.append(acc)\n",
    "        post_sens_list.append(sens)\n",
    "        post_spec_list.append(spec)\n",
    "\n",
    "    pre_acc_df = pd.DataFrame(np.asarray(pre_acc_list).T, columns=cent_names)\n",
    "    pre_sens_df = pd.DataFrame(np.asarray(pre_sens_list).T, columns=cent_names)\n",
    "    pre_spec_df = pd.DataFrame(np.asarray(pre_spec_list).T, columns=cent_names)\n",
    "\n",
    "    post_acc_df = pd.DataFrame(np.asarray(post_acc_list).T, columns=cent_names)\n",
    "    post_sens_df = pd.DataFrame(np.asarray(post_sens_list).T, columns=cent_names)\n",
    "    post_spec_df = pd.DataFrame(np.asarray(post_spec_list).T, columns=cent_names)\n",
    "\n",
    "    print(\"************** Pre-TL Accuracy **************\")\n",
    "    print(\"Mean\")\n",
    "    print(pre_acc_df.mean())\n",
    "    print(\"Standard Deviation\")\n",
    "    print(pre_acc_df.std())\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"************** Post-TL Accuracy **************\")\n",
    "    print(\"Mean\")\n",
    "    print(post_acc_df.mean())\n",
    "    print(\"Standard Deviation\")\n",
    "    print(post_acc_df.std())\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"************** Pre-TL Sensitivity **************\")\n",
    "    print(\"Mean\")\n",
    "    print(pre_sens_df.mean())\n",
    "    print(\"Standard Deviation\")\n",
    "    print(pre_sens_df.std())\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"************** Post-TL Sensitivity **************\")\n",
    "    print(\"Mean\")\n",
    "    print(post_sens_df.mean())\n",
    "    print(\"Standard Deviation\")\n",
    "    print(post_sens_df.std())\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"************** Pre-TL Specificity **************\")\n",
    "    print(\"Mean\")\n",
    "    print(pre_spec_df.mean())\n",
    "    print(\"Standard Deviation\")\n",
    "    print(pre_spec_df.std())\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"************** Post-TL Specificity **************\")\n",
    "    print(\"Mean\")\n",
    "    print(post_spec_df.mean())\n",
    "    print(\"Standard Deviation\")\n",
    "    print(post_spec_df.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** Pre-TL Accuracy **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.504187\n",
      "Riemannian\\nMean      0.714008\n",
      "Matrix\\nMedian        0.498770\n",
      "Riemannian\\nMedian    0.728532\n",
      "Huber\\nCentroid       0.737857\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.193544\n",
      "Riemannian\\nMean      0.046411\n",
      "Matrix\\nMedian        0.179467\n",
      "Riemannian\\nMedian    0.057553\n",
      "Huber\\nCentroid       0.069797\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Post-TL Accuracy **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.555000\n",
      "Riemannian\\nMean      0.762103\n",
      "Matrix\\nMedian        0.585159\n",
      "Riemannian\\nMedian    0.783889\n",
      "Huber\\nCentroid       0.788988\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.215600\n",
      "Riemannian\\nMean      0.053674\n",
      "Matrix\\nMedian        0.165298\n",
      "Riemannian\\nMedian    0.053607\n",
      "Huber\\nCentroid       0.056967\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Pre-TL Sensitivity **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.779881\n",
      "Riemannian\\nMean      0.572024\n",
      "Matrix\\nMedian        0.796190\n",
      "Riemannian\\nMedian    0.507262\n",
      "Huber\\nCentroid       0.450833\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.228183\n",
      "Riemannian\\nMean      0.158395\n",
      "Matrix\\nMedian        0.206167\n",
      "Riemannian\\nMedian    0.175746\n",
      "Huber\\nCentroid       0.250491\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Post-TL Sensitivity **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.760119\n",
      "Riemannian\\nMean      0.493571\n",
      "Matrix\\nMedian        0.757143\n",
      "Riemannian\\nMedian    0.400833\n",
      "Huber\\nCentroid       0.361905\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.219580\n",
      "Riemannian\\nMean      0.095248\n",
      "Matrix\\nMedian        0.186678\n",
      "Riemannian\\nMedian    0.171970\n",
      "Huber\\nCentroid       0.213665\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Pre-TL Specificity **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.449048\n",
      "Riemannian\\nMean      0.742405\n",
      "Matrix\\nMedian        0.439286\n",
      "Riemannian\\nMedian    0.772786\n",
      "Huber\\nCentroid       0.795262\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.273905\n",
      "Riemannian\\nMean      0.072463\n",
      "Matrix\\nMedian        0.251552\n",
      "Riemannian\\nMedian    0.094725\n",
      "Huber\\nCentroid       0.127819\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Post-TL Specificity **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.513976\n",
      "Riemannian\\nMean      0.815810\n",
      "Matrix\\nMedian        0.550762\n",
      "Riemannian\\nMedian    0.860500\n",
      "Huber\\nCentroid       0.874405\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.297168\n",
      "Riemannian\\nMean      0.057586\n",
      "Matrix\\nMedian        0.228484\n",
      "Riemannian\\nMedian    0.080649\n",
      "Huber\\nCentroid       0.095743\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_res_stats('session', session_chance_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** Pre-TL Accuracy **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.427123\n",
      "Riemannian\\nMean      0.685055\n",
      "Matrix\\nMedian        0.416538\n",
      "Riemannian\\nMedian    0.714330\n",
      "Huber\\nCentroid       0.734311\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.213367\n",
      "Riemannian\\nMean      0.106657\n",
      "Matrix\\nMedian        0.199064\n",
      "Riemannian\\nMedian    0.101810\n",
      "Huber\\nCentroid       0.098913\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Post-TL Accuracy **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.536086\n",
      "Riemannian\\nMean      0.783150\n",
      "Matrix\\nMedian        0.544365\n",
      "Riemannian\\nMedian    0.799306\n",
      "Huber\\nCentroid       0.804762\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.234236\n",
      "Riemannian\\nMean      0.028581\n",
      "Matrix\\nMedian        0.220971\n",
      "Riemannian\\nMedian    0.031849\n",
      "Huber\\nCentroid       0.034045\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Pre-TL Sensitivity **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.807321\n",
      "Riemannian\\nMean      0.514732\n",
      "Matrix\\nMedian        0.828780\n",
      "Riemannian\\nMedian    0.439613\n",
      "Huber\\nCentroid       0.374524\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.222730\n",
      "Riemannian\\nMean      0.284571\n",
      "Matrix\\nMedian        0.188317\n",
      "Riemannian\\nMedian    0.284300\n",
      "Huber\\nCentroid       0.299150\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Post-TL Sensitivity **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.727976\n",
      "Riemannian\\nMean      0.396815\n",
      "Matrix\\nMedian        0.732113\n",
      "Riemannian\\nMedian    0.323244\n",
      "Huber\\nCentroid       0.285982\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.244336\n",
      "Riemannian\\nMean      0.157323\n",
      "Matrix\\nMedian        0.217579\n",
      "Riemannian\\nMedian    0.217928\n",
      "Huber\\nCentroid       0.228760\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Pre-TL Specificity **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.351083\n",
      "Riemannian\\nMean      0.719119\n",
      "Matrix\\nMedian        0.334089\n",
      "Riemannian\\nMedian    0.769274\n",
      "Huber\\nCentroid       0.806268\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.297603\n",
      "Riemannian\\nMean      0.180258\n",
      "Matrix\\nMedian        0.274044\n",
      "Riemannian\\nMedian    0.174551\n",
      "Huber\\nCentroid       0.175085\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Post-TL Specificity **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.497708\n",
      "Riemannian\\nMean      0.860417\n",
      "Matrix\\nMedian        0.506815\n",
      "Riemannian\\nMedian    0.894518\n",
      "Huber\\nCentroid       0.908518\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.325040\n",
      "Riemannian\\nMean      0.042326\n",
      "Matrix\\nMedian        0.304235\n",
      "Riemannian\\nMedian    0.071157\n",
      "Huber\\nCentroid       0.076926\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_res_stats('subject', subject_chance_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** Pre-TL Accuracy **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.330952\n",
      "Riemannian\\nMean      0.514683\n",
      "Matrix\\nMedian        0.292143\n",
      "Riemannian\\nMedian    0.630040\n",
      "Huber\\nCentroid       0.552183\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.120970\n",
      "Riemannian\\nMean      0.208733\n",
      "Matrix\\nMedian        0.099579\n",
      "Riemannian\\nMedian    0.209532\n",
      "Huber\\nCentroid       0.260259\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Post-TL Accuracy **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.760040\n",
      "Riemannian\\nMean      0.839325\n",
      "Matrix\\nMedian        0.770317\n",
      "Riemannian\\nMedian    0.836587\n",
      "Huber\\nCentroid       0.836548\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.104378\n",
      "Riemannian\\nMean      0.004862\n",
      "Matrix\\nMedian        0.091013\n",
      "Riemannian\\nMedian    0.004865\n",
      "Huber\\nCentroid       0.004478\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Pre-TL Sensitivity **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.909762\n",
      "Riemannian\\nMean      0.675952\n",
      "Matrix\\nMedian        0.935952\n",
      "Riemannian\\nMedian    0.498095\n",
      "Huber\\nCentroid       0.566429\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.094830\n",
      "Riemannian\\nMean      0.283136\n",
      "Matrix\\nMedian        0.069874\n",
      "Riemannian\\nMedian    0.347746\n",
      "Huber\\nCentroid       0.358727\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Post-TL Sensitivity **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.339286\n",
      "Riemannian\\nMean      0.083333\n",
      "Matrix\\nMedian        0.315714\n",
      "Riemannian\\nMedian    0.029048\n",
      "Huber\\nCentroid       0.031429\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.274273\n",
      "Riemannian\\nMean      0.032093\n",
      "Matrix\\nMedian        0.257700\n",
      "Riemannian\\nMedian    0.041077\n",
      "Huber\\nCentroid       0.047679\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Pre-TL Specificity **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.215190\n",
      "Riemannian\\nMean      0.482429\n",
      "Matrix\\nMedian        0.163381\n",
      "Riemannian\\nMedian    0.656429\n",
      "Huber\\nCentroid       0.549333\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.163389\n",
      "Riemannian\\nMean      0.304915\n",
      "Matrix\\nMedian        0.132968\n",
      "Riemannian\\nMedian    0.319287\n",
      "Huber\\nCentroid       0.382326\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "************** Post-TL Specificity **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.844190\n",
      "Riemannian\\nMean      0.990524\n",
      "Matrix\\nMedian        0.861238\n",
      "Riemannian\\nMedian    0.998095\n",
      "Huber\\nCentroid       0.997571\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.179363\n",
      "Riemannian\\nMean      0.004320\n",
      "Matrix\\nMedian        0.159937\n",
      "Riemannian\\nMedian    0.002658\n",
      "Huber\\nCentroid       0.005540\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_res_stats('task', task_chance_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_change_res(file_type):\n",
    "\n",
    "    cent_opts = ['euclid_mean', 'riemann_mean', 'mat_med', 'riemann_med', 'huber']\n",
    "    cent_names = [\"Euclidean\\nMean\", \"Riemannian\\nMean\", \"Matrix\\nMedian\", \"Riemannian\\nMedian\", \"Huber\\nCentroid\"]\n",
    "\n",
    "    pre_acc_list = []\n",
    "    pre_sens_list = []\n",
    "    pre_spec_list = []\n",
    "    for cent in cent_opts: \n",
    "        acc, sens, spec = get_data(\"results/pre_\" + file_type + \"_\" + cent + \".csv\")\n",
    "        pre_acc_list.append(acc)\n",
    "        pre_sens_list.append(sens)\n",
    "        pre_spec_list.append(spec)\n",
    "\n",
    "    post_acc_list = []\n",
    "    post_sens_list = []\n",
    "    post_spec_list = []\n",
    "    for cent in cent_opts: \n",
    "        acc, sens, spec = get_data(\"results/post_\" + file_type + \"_\" + cent + \".csv\")\n",
    "        post_acc_list.append(acc)\n",
    "        post_sens_list.append(sens)\n",
    "        post_spec_list.append(spec)\n",
    "\n",
    "    change_acc_df = pd.DataFrame((np.asarray(post_acc_list).T - np.asarray(pre_acc_list).T)/np.asarray(pre_acc_list).T, columns=cent_names)\n",
    "    change_sens_df = pd.DataFrame((np.asarray(post_sens_list).T - np.asarray(pre_sens_list).T)/np.asarray(pre_sens_list).T, columns=cent_names)\n",
    "    change_spec_df = pd.DataFrame((np.asarray(post_spec_list).T - np.asarray(pre_spec_list).T)/np.asarray(pre_spec_list).T, columns=cent_names)\n",
    "\n",
    "    print(\"************** Accuracy **************\")\n",
    "    print(\"Mean\")\n",
    "    print(change_acc_df.mean())\n",
    "    print(\"Standard Deviation\")\n",
    "    print(change_acc_df.std())\n",
    "\n",
    "    print(\"************** Sensitivity **************\")\n",
    "    print(\"Mean\")\n",
    "    print(change_sens_df.mean())\n",
    "    print(\"Standard Deviation\")\n",
    "    print(change_sens_df.std())\n",
    "\n",
    "    print(\"************** Specificity **************\")\n",
    "    print(\"Mean\")\n",
    "    print(change_spec_df.mean())\n",
    "    print(\"Standard Deviation\")\n",
    "    print(change_spec_df.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** Accuracy **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.123013\n",
      "Riemannian\\nMean      0.071780\n",
      "Matrix\\nMedian        0.224485\n",
      "Riemannian\\nMedian    0.080471\n",
      "Huber\\nCentroid       0.075877\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.310994\n",
      "Riemannian\\nMean      0.104674\n",
      "Matrix\\nMedian        0.267703\n",
      "Riemannian\\nMedian    0.093718\n",
      "Huber\\nCentroid       0.104853\n",
      "dtype: float64\n",
      "************** Sensitivity **************\n",
      "Mean\n",
      "Euclidean\\nMean      -0.011656\n",
      "Riemannian\\nMean     -0.095213\n",
      "Matrix\\nMedian       -0.035032\n",
      "Riemannian\\nMedian   -0.210694\n",
      "Huber\\nCentroid      -0.193790\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.133634\n",
      "Riemannian\\nMean      0.210216\n",
      "Matrix\\nMedian        0.109924\n",
      "Riemannian\\nMedian    0.288187\n",
      "Huber\\nCentroid       0.416401\n",
      "dtype: float64\n",
      "************** Specificity **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.241245\n",
      "Riemannian\\nMean      0.112546\n",
      "Matrix\\nMedian        0.463980\n",
      "Riemannian\\nMedian    0.125691\n",
      "Huber\\nCentroid       0.118543\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.625097\n",
      "Riemannian\\nMean      0.162430\n",
      "Matrix\\nMedian        0.654112\n",
      "Riemannian\\nMedian    0.145820\n",
      "Huber\\nCentroid       0.168006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_change_res('session')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** Accuracy **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.295370\n",
      "Riemannian\\nMean      0.174689\n",
      "Matrix\\nMedian        0.357927\n",
      "Riemannian\\nMedian    0.145888\n",
      "Huber\\nCentroid       0.119081\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.348967\n",
      "Riemannian\\nMean      0.213193\n",
      "Matrix\\nMedian        0.367028\n",
      "Riemannian\\nMedian    0.203830\n",
      "Huber\\nCentroid       0.185319\n",
      "dtype: float64\n",
      "************** Sensitivity **************\n",
      "Mean\n",
      "Euclidean\\nMean      -0.106807\n",
      "Riemannian\\nMean           inf\n",
      "Matrix\\nMedian       -0.125974\n",
      "Riemannian\\nMedian         inf\n",
      "Huber\\nCentroid            inf\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.124195\n",
      "Riemannian\\nMean           NaN\n",
      "Matrix\\nMedian        0.117461\n",
      "Riemannian\\nMedian         NaN\n",
      "Huber\\nCentroid            NaN\n",
      "dtype: float64\n",
      "************** Specificity **************\n",
      "Mean\n",
      "Euclidean\\nMean       0.935176\n",
      "Riemannian\\nMean      0.281514\n",
      "Matrix\\nMedian        1.478456\n",
      "Riemannian\\nMedian    0.233489\n",
      "Huber\\nCentroid       0.187440\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       2.978028\n",
      "Riemannian\\nMean      0.374192\n",
      "Matrix\\nMedian        4.652030\n",
      "Riemannian\\nMedian    0.363060\n",
      "Huber\\nCentroid       0.321355\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanna\\AppData\\Local\\Temp\\ipykernel_36980\\4244658924.py:25: RuntimeWarning: divide by zero encountered in divide\n",
      "  change_sens_df = pd.DataFrame((np.asarray(post_sens_list).T - np.asarray(pre_sens_list).T)/np.asarray(pre_sens_list).T, columns=cent_names)\n",
      "C:\\Users\\hanna\\AppData\\Local\\Temp\\ipykernel_36980\\4244658924.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  change_sens_df = pd.DataFrame((np.asarray(post_sens_list).T - np.asarray(pre_sens_list).T)/np.asarray(pre_sens_list).T, columns=cent_names)\n",
      "c:\\Users\\hanna\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    }
   ],
   "source": [
    "get_change_res('subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** Accuracy **************\n",
      "Mean\n",
      "Euclidean\\nMean       1.610547\n",
      "Riemannian\\nMean      0.969092\n",
      "Matrix\\nMedian        1.946434\n",
      "Riemannian\\nMedian    0.513839\n",
      "Huber\\nCentroid       1.041128\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.933319\n",
      "Riemannian\\nMean      0.963136\n",
      "Matrix\\nMedian        0.977507\n",
      "Riemannian\\nMedian    0.595508\n",
      "Huber\\nCentroid       1.213022\n",
      "dtype: float64\n",
      "************** Sensitivity **************\n",
      "Mean\n",
      "Euclidean\\nMean      -0.622704\n",
      "Riemannian\\nMean     -0.835567\n",
      "Matrix\\nMedian       -0.657796\n",
      "Riemannian\\nMedian   -0.940782\n",
      "Huber\\nCentroid      -0.949586\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean       0.307494\n",
      "Riemannian\\nMean      0.136019\n",
      "Matrix\\nMedian        0.284945\n",
      "Riemannian\\nMedian    0.061737\n",
      "Huber\\nCentroid       0.052689\n",
      "dtype: float64\n",
      "************** Specificity **************\n",
      "Mean\n",
      "Euclidean\\nMean       18.868321\n",
      "Riemannian\\nMean       3.477842\n",
      "Matrix\\nMedian        74.163391\n",
      "Riemannian\\nMedian     1.121484\n",
      "Huber\\nCentroid        4.824888\n",
      "dtype: float64\n",
      "Standard Deviation\n",
      "Euclidean\\nMean        30.952849\n",
      "Riemannian\\nMean        6.198171\n",
      "Matrix\\nMedian        174.287698\n",
      "Riemannian\\nMedian      1.347894\n",
      "Huber\\nCentroid         8.523992\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_change_res('task')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
